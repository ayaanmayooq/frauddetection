{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-21T19:42:22.687020Z",
     "start_time": "2024-11-21T19:42:22.675596Z"
    }
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report, roc_auc_score\n",
    "import seaborn as sns\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T19:46:11.960064Z",
     "start_time": "2024-11-21T19:46:11.947023Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_metrics(y_true, y_pred):\n",
    "    # ROC Curve and AUC\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "    roc_auc = roc_auc_score(y_true, y_pred)\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    fnr = cm[1][0] / (cm[1][0] + cm[1][1])  # False Negative Rate\n",
    "    precision = cm[1][1] / (cm[1][1] + cm[0][1]) if (cm[1][1] + cm[0][1]) != 0 else 0\n",
    "    recall = cm[1][1] / (cm[1][1] + cm[1][0])\n",
    "\n",
    "    return {\n",
    "        \"roc_auc\": roc_auc,\n",
    "        \"fnr\": fnr,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"fpr\": fpr,\n",
    "        \"tpr\": tpr,\n",
    "    }\n"
   ],
   "id": "24a12b301ad8a81b",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T19:46:29.101747Z",
     "start_time": "2024-11-21T19:46:29.096032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_confusion_matrix(cm, model_name):\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False, square=True)\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.title(f\"Confusion Matrix: {model_name}\")\n",
    "    plt.savefig(f\"artifacts/{model_name}_confusion_matrix.png\")\n",
    "    plt.close()\n",
    "\n"
   ],
   "id": "24cd21f20ae80d3",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T19:46:30.189730Z",
     "start_time": "2024-11-21T19:46:30.181866Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_roc_curve(fpr, tpr, roc_auc, model_name):\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label=f\"ROC Curve (AUC = {roc_auc:.2f})\")\n",
    "    plt.plot([0, 1], [0, 1], \"k--\", label=\"Random Guess\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(f\"ROC Curve for {model_name}\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(f\"artifacts/{model_name}_roc_curve.png\")\n",
    "    plt.close()\n"
   ],
   "id": "da50811d97fbe425",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T19:46:31.227788Z",
     "start_time": "2024-11-21T19:46:31.219046Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_model_comparison(metrics_df, metric_x=\"fnr\", metric_y=\"roc_auc\"):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for _, row in metrics_df.iterrows():\n",
    "        plt.scatter(row[metric_x], row[metric_y], label=row[\"model\"], s=100)\n",
    "        plt.text(row[metric_x], row[metric_y], row[\"model\"], fontsize=9, ha=\"right\")\n",
    "    plt.xlabel(metric_x.upper())\n",
    "    plt.ylabel(metric_y.upper())\n",
    "    plt.title(f\"Model Comparison: {metric_x.upper()} vs {metric_y.upper()}\")\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"artifacts/model_comparison_scatter.png\")\n",
    "    plt.close()\n",
    "    print(\"Model comparison scatter plot saved!\")\n"
   ],
   "id": "f91bb0b46cbe8958",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T19:46:32.228156Z",
     "start_time": "2024-11-21T19:46:32.217549Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_plots_and_metrics(prediction_folder=\"artifacts/predictions\"):\n",
    "    model_metrics = []\n",
    "\n",
    "    # Iterate over prediction files\n",
    "    for file in os.listdir(prediction_folder):\n",
    "        if file.endswith(\".csv\"):\n",
    "            model_name = file.replace(\"_predictions.csv\", \"\")\n",
    "            print(f\"Processing predictions for: {model_name}\")\n",
    "\n",
    "            # Load predictions\n",
    "            predictions = pd.read_csv(os.path.join(prediction_folder, file))\n",
    "            y_true = predictions[\"y_true\"]\n",
    "            y_pred = predictions[\"y_pred\"]\n",
    "\n",
    "            # Compute metrics\n",
    "            metrics = compute_metrics(y_true, y_pred)\n",
    "            metrics[\"model\"] = model_name\n",
    "            model_metrics.append(metrics)\n",
    "\n",
    "            # Plot ROC Curve\n",
    "            plot_roc_curve(metrics[\"fpr\"], metrics[\"tpr\"], metrics[\"roc_auc\"], model_name)\n",
    "\n",
    "            # Plot Confusion Matrix\n",
    "            cm = confusion_matrix(y_true, y_pred)\n",
    "            plot_confusion_matrix(cm, model_name)\n",
    "\n",
    "    # Create scatter plot for model comparison\n",
    "    metrics_df = pd.DataFrame(model_metrics)\n",
    "    plot_model_comparison(metrics_df, metric_x=\"fnr\", metric_y=\"roc_auc\")\n"
   ],
   "id": "bbd8fce68d5c207a",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T19:46:34.739519Z",
     "start_time": "2024-11-21T19:46:33.215470Z"
    }
   },
   "cell_type": "code",
   "source": "generate_plots_and_metrics()",
   "id": "c5972071cb48752b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing predictions for: random_forest\n",
      "Processing predictions for: logistic_regression\n",
      "Model comparison scatter plot saved!\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3716fc96d10d4155"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
