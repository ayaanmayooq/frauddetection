{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-28T18:36:06.955145Z",
     "start_time": "2024-11-28T18:36:03.369492300Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, precision_recall_curve, accuracy_score, roc_auc_score, log_loss\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src.data_prep import prepare_data\n",
    "# from src.models import logistic_regression_model, decision_tree_model, random_forest_model, lightgbm_model\n",
    "# from src.train import train_sklearn_model\n",
    "from src.evaluation import evaluate_model\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import joblib\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "           Time        V1        V2        V3        V4        V5        V6  \\\n83225   59741.0 -1.648591  1.228130  1.370169 -1.735542 -0.029455 -0.484129   \n52800   45648.0 -0.234775 -0.493269  1.236728 -2.338793 -1.176733  0.885733   \n21293   31579.0  1.134626 -0.774460 -0.163390 -0.533358 -0.604555 -0.244482   \n133600  80455.0  0.069514  1.017753  1.033117  1.384376  0.223233 -0.310845   \n38225   39302.0 -0.199441  0.610092 -0.114437  0.256565  2.290752  4.008475   \n\n              V7        V8        V9  ...       V20       V21       V22  \\\n83225   0.918645 -0.438750  0.982144  ...  0.384201 -0.218076 -0.203458   \n52800  -1.960981 -2.363412 -2.694774  ...  0.364679 -1.495358 -0.083066   \n21293  -0.212682  0.040782 -1.136627  ... -0.396476 -0.684454 -1.855269   \n133600  0.597287 -0.127658 -0.701533  ...  0.148760  0.097023  0.369957   \n38225  -0.123530  1.038374 -0.075846  ...  0.292972 -0.019733  0.165463   \n\n             V23       V24       V25       V26       V27       V28  Amount  \n83225  -0.213015  0.011372 -0.304481  0.632063 -0.262968 -0.099863   38.42  \n52800   0.074612 -0.347329  0.541900 -0.433294  0.089293  0.212029   61.20  \n21293   0.171997 -0.387783 -0.062985  0.245118 -0.061178  0.012180  110.95  \n133600 -0.219266 -0.124941 -0.049749 -0.112946  0.114440  0.066101   10.00  \n38225  -0.080978  1.020656 -0.300730 -0.269595  0.481769  0.254114   22.00  \n\n[5 rows x 30 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V20</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>83225</th>\n      <td>59741.0</td>\n      <td>-1.648591</td>\n      <td>1.228130</td>\n      <td>1.370169</td>\n      <td>-1.735542</td>\n      <td>-0.029455</td>\n      <td>-0.484129</td>\n      <td>0.918645</td>\n      <td>-0.438750</td>\n      <td>0.982144</td>\n      <td>...</td>\n      <td>0.384201</td>\n      <td>-0.218076</td>\n      <td>-0.203458</td>\n      <td>-0.213015</td>\n      <td>0.011372</td>\n      <td>-0.304481</td>\n      <td>0.632063</td>\n      <td>-0.262968</td>\n      <td>-0.099863</td>\n      <td>38.42</td>\n    </tr>\n    <tr>\n      <th>52800</th>\n      <td>45648.0</td>\n      <td>-0.234775</td>\n      <td>-0.493269</td>\n      <td>1.236728</td>\n      <td>-2.338793</td>\n      <td>-1.176733</td>\n      <td>0.885733</td>\n      <td>-1.960981</td>\n      <td>-2.363412</td>\n      <td>-2.694774</td>\n      <td>...</td>\n      <td>0.364679</td>\n      <td>-1.495358</td>\n      <td>-0.083066</td>\n      <td>0.074612</td>\n      <td>-0.347329</td>\n      <td>0.541900</td>\n      <td>-0.433294</td>\n      <td>0.089293</td>\n      <td>0.212029</td>\n      <td>61.20</td>\n    </tr>\n    <tr>\n      <th>21293</th>\n      <td>31579.0</td>\n      <td>1.134626</td>\n      <td>-0.774460</td>\n      <td>-0.163390</td>\n      <td>-0.533358</td>\n      <td>-0.604555</td>\n      <td>-0.244482</td>\n      <td>-0.212682</td>\n      <td>0.040782</td>\n      <td>-1.136627</td>\n      <td>...</td>\n      <td>-0.396476</td>\n      <td>-0.684454</td>\n      <td>-1.855269</td>\n      <td>0.171997</td>\n      <td>-0.387783</td>\n      <td>-0.062985</td>\n      <td>0.245118</td>\n      <td>-0.061178</td>\n      <td>0.012180</td>\n      <td>110.95</td>\n    </tr>\n    <tr>\n      <th>133600</th>\n      <td>80455.0</td>\n      <td>0.069514</td>\n      <td>1.017753</td>\n      <td>1.033117</td>\n      <td>1.384376</td>\n      <td>0.223233</td>\n      <td>-0.310845</td>\n      <td>0.597287</td>\n      <td>-0.127658</td>\n      <td>-0.701533</td>\n      <td>...</td>\n      <td>0.148760</td>\n      <td>0.097023</td>\n      <td>0.369957</td>\n      <td>-0.219266</td>\n      <td>-0.124941</td>\n      <td>-0.049749</td>\n      <td>-0.112946</td>\n      <td>0.114440</td>\n      <td>0.066101</td>\n      <td>10.00</td>\n    </tr>\n    <tr>\n      <th>38225</th>\n      <td>39302.0</td>\n      <td>-0.199441</td>\n      <td>0.610092</td>\n      <td>-0.114437</td>\n      <td>0.256565</td>\n      <td>2.290752</td>\n      <td>4.008475</td>\n      <td>-0.123530</td>\n      <td>1.038374</td>\n      <td>-0.075846</td>\n      <td>...</td>\n      <td>0.292972</td>\n      <td>-0.019733</td>\n      <td>0.165463</td>\n      <td>-0.080978</td>\n      <td>1.020656</td>\n      <td>-0.300730</td>\n      <td>-0.269595</td>\n      <td>0.481769</td>\n      <td>0.254114</td>\n      <td>22.00</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 30 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/creditcard/creditcard.csv')\n",
    "X = df.drop(columns='Class')\n",
    "y = df['Class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_fit, X_val, y_fit, y_val = train_test_split(\n",
    "    X_train, y_train,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-28T18:36:40.617739500Z",
     "start_time": "2024-11-28T18:36:38.695972300Z"
    }
   },
   "id": "304a2f19fb78401d",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 283, number of negative: 159920\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012547 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7650\n",
      "[LightGBM] [Info] Number of data points in the train set: 160203, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.001767 -> initscore=-6.336982\n",
      "[LightGBM] [Info] Start training from score -6.336982\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[100]\tfit's binary_logloss: 0.0018981\tval's binary_logloss: 0.0035569\n",
      "[200]\tfit's binary_logloss: 0.00080822\tval's binary_logloss: 0.00283644\n",
      "[300]\tfit's binary_logloss: 0.000396519\tval's binary_logloss: 0.00264941\n",
      "Early stopping, best iteration is:\n",
      "[352]\tfit's binary_logloss: 0.000281286\tval's binary_logloss: 0.00261413\n",
      "\n",
      "Test's ROC AUC: 0.97772\n",
      "Test's logloss: 0.00237\n"
     ]
    }
   ],
   "source": [
    "fit = lgb.Dataset(X_fit, y_fit)\n",
    "val = lgb.Dataset(X_val, y_val, reference=fit)\n",
    "\n",
    "model = lgb.train(\n",
    "    params={\n",
    "        'learning_rate': 0.01,\n",
    "        'objective': 'binary'\n",
    "    },\n",
    "    train_set=fit,\n",
    "    num_boost_round=400,\n",
    "    valid_sets=(fit, val),\n",
    "    valid_names=('fit', 'val'),\n",
    "  callbacks=[\n",
    "    lgb.early_stopping(stopping_rounds=20),\n",
    "    lgb.log_evaluation(period=100)\n",
    "    ]\n",
    ")\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print()\n",
    "print(f\"Test's ROC AUC: {roc_auc_score(y_test, y_pred):.5f}\")\n",
    "print(f\"Test's logloss: {log_loss(y_test, y_pred):.5f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-28T18:57:26.719064Z",
     "start_time": "2024-11-28T18:57:23.280885400Z"
    }
   },
   "id": "7ab3919d456bbeea",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Threshold: 0.00080\n",
      "Binary predictions saved successfully!\n"
     ]
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "# Convert continuous predictions to binary predictions based on the optimal threshold\n",
    "y_pred_binary = (y_pred >= 0.5).astype(int)\n",
    "\n",
    "# Save binary predictions and true labels\n",
    "binary_predictions = pd.DataFrame({\"y_true\": y_test, \"y_pred\": y_pred_binary})\n",
    "binary_predictions.to_csv(\"artifacts/predictions/lightgbm_predictions_bce.csv\", index=False)\n",
    "\n",
    "print(f\"Optimal Threshold: {optimal_threshold:.5f}\")\n",
    "print(\"Binary predictions saved successfully!\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-28T18:57:26.789326300Z",
     "start_time": "2024-11-28T18:57:26.722607200Z"
    }
   },
   "id": "475ac7123eb26889",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import optimize\n",
    "from scipy import special\n",
    "\n",
    "class FocalLoss:\n",
    "\n",
    "    def __init__(self, gamma, alpha=None):\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def at(self, y):\n",
    "        if self.alpha is None:\n",
    "            return np.ones_like(y)\n",
    "        return np.where(y, self.alpha, 1 - self.alpha)\n",
    "\n",
    "    def pt(self, y, p):\n",
    "        p = np.clip(p, 1e-15, 1 - 1e-15)\n",
    "        return np.where(y, p, 1 - p)\n",
    "\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        at = self.at(y_true)\n",
    "        pt = self.pt(y_true, y_pred)\n",
    "        return -at * (1 - pt) ** self.gamma * np.log(pt)\n",
    "\n",
    "    def grad(self, y_true, y_pred):\n",
    "        y = 2 * y_true - 1  # {0, 1} -> {-1, 1}\n",
    "        at = self.at(y_true)\n",
    "        pt = self.pt(y_true, y_pred)\n",
    "        g = self.gamma\n",
    "        return at * y * (1 - pt) ** g * (g * pt * np.log(pt) + pt - 1)\n",
    "\n",
    "    def hess(self, y_true, y_pred):\n",
    "        y = 2 * y_true - 1  # {0, 1} -> {-1, 1}\n",
    "        at = self.at(y_true)\n",
    "        pt = self.pt(y_true, y_pred)\n",
    "        g = self.gamma\n",
    "\n",
    "        u = at * y * (1 - pt) ** g\n",
    "        du = -at * y * g * (1 - pt) ** (g - 1)\n",
    "        v = g * pt * np.log(pt) + pt - 1\n",
    "        dv = g * np.log(pt) + g + 1\n",
    "\n",
    "        return (du * v + u * dv) * y * (pt * (1 - pt))\n",
    "\n",
    "    def init_score(self, y_true):\n",
    "        res = optimize.minimize_scalar(\n",
    "            lambda p: self(y_true, p).sum(),\n",
    "            bounds=(0, 1),\n",
    "            method='bounded'\n",
    "        )\n",
    "        p = res.x\n",
    "        log_odds = np.log(p / (1 - p))\n",
    "        return log_odds\n",
    "\n",
    "    def lgb_obj(self, preds, train_data):\n",
    "        y = train_data.get_label()\n",
    "        p = special.expit(preds)\n",
    "        return self.grad(y, p), self.hess(y, p)\n",
    "\n",
    "    def lgb_eval(self, preds, train_data):\n",
    "        y = train_data.get_label()\n",
    "        p = special.expit(preds)\n",
    "        is_higher_better = False\n",
    "        return 'focal_loss', self(y, p).mean(), is_higher_better"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-28T18:57:26.829624500Z",
     "start_time": "2024-11-28T18:57:26.797932200Z"
    }
   },
   "id": "39d80f1b41e49891",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Using self-defined objective function\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011478 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7650\n",
      "[LightGBM] [Info] Number of data points in the train set: 160203, number of used features: 30\n",
      "[LightGBM] [Info] Using self-defined objective function\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[100]\tfit's focal_loss: 0.00190475\tval's focal_loss: 0.00356043\n",
      "[200]\tfit's focal_loss: 0.000811846\tval's focal_loss: 0.00285806\n",
      "[300]\tfit's focal_loss: 0.000401933\tval's focal_loss: 0.00267161\n",
      "Early stopping, best iteration is:\n",
      "[345]\tfit's focal_loss: 0.000297174\tval's focal_loss: 0.00263719\n",
      "\n",
      "Test's ROC AUC: 0.97948\n",
      "Test's logloss: 0.00237\n"
     ]
    }
   ],
   "source": [
    "fl = FocalLoss(alpha=None, gamma=0)\n",
    "\n",
    "fit = lgb.Dataset(\n",
    "    X_fit, y_fit,\n",
    "    init_score=np.full_like(y_fit, fl.init_score(y_fit), dtype=float)\n",
    ")\n",
    "\n",
    "val = lgb.Dataset(\n",
    "    X_val, y_val,\n",
    "    init_score=np.full_like(y_val, fl.init_score(y_fit), dtype=float),\n",
    "    reference=fit\n",
    ")\n",
    "\n",
    "model = lgb.train(\n",
    "    params={\n",
    "        'learning_rate': 0.01,\n",
    "        'objective': fl.lgb_obj\n",
    "    },\n",
    "    train_set=fit,\n",
    "    num_boost_round=10000,\n",
    "    valid_sets=(fit, val),\n",
    "    valid_names=('fit', 'val'),\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(stopping_rounds=20),\n",
    "        lgb.log_evaluation(period=100)\n",
    "    ],\n",
    "    feval=fl.lgb_eval\n",
    ")\n",
    "\n",
    "y_pred = special.expit(fl.init_score(y_fit) + model.predict(X_test))\n",
    "\n",
    "print()\n",
    "print(f\"Test's ROC AUC: {roc_auc_score(y_test, y_pred):.5f}\")\n",
    "print(f\"Test's logloss: {log_loss(y_test, y_pred):.5f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-28T18:58:05.571810600Z",
     "start_time": "2024-11-28T18:57:26.824521900Z"
    }
   },
   "id": "40026623f755db8d",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Threshold: 0.00074\n",
      "Binary predictions saved successfully!\n"
     ]
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "# Convert continuous predictions to binary predictions based on the optimal threshold\n",
    "y_pred_binary = (y_pred >= 0.5).astype(int)\n",
    "\n",
    "# Save binary predictions and true labels\n",
    "binary_predictions = pd.DataFrame({\"y_true\": y_test, \"y_pred\": y_pred_binary})\n",
    "binary_predictions.to_csv(\"artifacts/predictions/lightgbm_predictions_focal_loss.csv\", index=False)\n",
    "\n",
    "print(f\"Optimal Threshold: {optimal_threshold:.5f}\")\n",
    "print(\"Binary predictions saved successfully!\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-28T18:58:05.635110500Z",
     "start_time": "2024-11-28T18:58:05.576249900Z"
    }
   },
   "id": "f4c42b6865dfb794",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "605e78ba3552d00"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
